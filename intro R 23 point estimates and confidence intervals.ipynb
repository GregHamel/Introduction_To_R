{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to R Part 23: Point Estimates and Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this point, this guide has focused on the functions and sytnax necessary to manipulate, explore and describe data in R. Data cleaning and exploratory analaysis are often prelimany steps toward the end goal of extracting insight from data through statistical inference or predictive modeling. The remainder of this guide will focus on methods for analyzing data and tools for carrying out analyses in R.\n",
    "\n",
    "Statistical inference is the process of analyzing sample data to gain insight into the population from which the data was collected and to investigate differences bewteen data samples. In data analyis, we are often interested in the characteristics of some large population, but collecting data on the entire population may be infeasbile. For example, leading up to U.S. presidential elections it could be very useful to know the political leanings of every single elgible voter, but surveying every voter is not feasible. Instead, we could poll some subample of the population, such as a thousand registered voters, and use that data to make inferences about the population as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point estimates are estimates of population parameters based on sample data. For instance, if we wanted to know the average age of registered voters in the U.S., we could take a survey of registered voters and then use the average age of the respondents as a point estimate of the average age of the population as a whole. The average of a sample is known as the sample mean.\n",
    "\n",
    "The sample mean is usually not exactly the same as the population mean. This difference can be caused by many factors including poor survey design, biased sampling methods and the randomness inherent to drawing a sample from a population. Let's investigate point estimates by generating a population of random age data and then drawing a sample from it to estimate the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "51.2188371860945"
      ],
      "text/latex": [
       "51.2188371860945"
      ],
      "text/markdown": [
       "51.2188371860945"
      ],
      "text/plain": [
       "[1] 51.21884"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set.seed(12)\n",
    "population_ages <- c(rexp(1000000,0.015)+18,   # generate a population\n",
    "                    rpois(500000,20)+18,\n",
    "                    rpois(500000,32.5)+18,\n",
    "                    rpois(500000,45)+18)\n",
    "\n",
    "population_ages <- ifelse(population_ages<100, population_ages, population_ages%%100+18)\n",
    "\n",
    "\n",
    "true_mean <- mean(population_ages)            # check the population mean\n",
    "\n",
    "true_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "52.1636089223386"
      ],
      "text/latex": [
       "52.1636089223386"
      ],
      "text/markdown": [
       "52.1636089223386"
      ],
      "text/plain": [
       "[1] 52.16361"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "0.944771736244064"
      ],
      "text/latex": [
       "0.944771736244064"
      ],
      "text/markdown": [
       "0.944771736244064"
      ],
      "text/plain": [
       "[1] 0.9447717"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set.seed(10)\n",
    "sample_ages <- sample(population_ages, size=1000)  # take a sample of 1000 ages\n",
    "\n",
    "sample_mean <- mean(sample_ages)            # make a point estimate of the mean\n",
    "\n",
    "sample_mean\n",
    "\n",
    "sample_mean-true_mean   # check difference bewteen the estimate and true population parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our point estimate based on a sample of 1000 individuals overestimates the true population mean by almost a year, but it is pretty close. This illustrates an important point: we can get a fairly accurate estimate of a large population by sampling a relatively small subset of individuals.\n",
    "\n",
    "Another point estimate that may be of interest is the proportion of the population that belongs to some category or subgroup. For example, we might like to know the race of each voter we poll, to get a sense of the overall demographics of the voter base. You can make a point estimate of this sort of proportion by taking a sample and then checking the ratio in the sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"white  proportion estimate:\"\n",
      "[1] 0.4\n",
      "[1] \"asian  proportion estimate:\"\n",
      "[1] 0.096\n",
      "[1] \"other  proportion estimate:\"\n",
      "[1] 0.093\n",
      "[1] \"black  proportion estimate:\"\n",
      "[1] 0.207\n",
      "[1] \"hispanic  proportion estimate:\"\n",
      "[1] 0.204\n"
     ]
    }
   ],
   "source": [
    "set.seed(12)\n",
    "population_races <- c(rep(\"white\",1000000),        # generate some dummy demographic data\n",
    "                      rep(\"hispanic\",500000),\n",
    "                      rep(\"black\",500000),\n",
    "                      rep(\"asian\",250000),\n",
    "                      rep(\"other\",250000))\n",
    "\n",
    "demographic_sample <- sample(population_races, size=1000)       # take a sample\n",
    "\n",
    "for (race in unique(demographic_sample)){            # loop over each race*\n",
    "    print(paste(race,\" proportion estimate:\"))       \n",
    "    print(sum(demographic_sample==race)/1000)        # print the estimated proportion\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: The function unique() takes a vector and returns a new vector with duplicate elements removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Distributions and The Central Limit Theorum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many statistical procedures assume that data follows a normal distribution, because the normal distribution has nice properties like symmetricity and having the majority of the data clustered witin a few standard deviations of the mean. Unfortunetly, real world data is often not normally distributed and the distribution of a sample tends to mirror the distribution of the population. This means a sample taken from a population with a skewed distribution will aslo tend to be skewed. Let's investigate by plotting the data and sample we createad earlier and by checking the skew:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(e1071)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.655602782446446"
      ],
      "text/latex": [
       "0.655602782446446"
      ],
      "text/markdown": [
       "0.655602782446446"
      ],
      "text/plain": [
       "[1] 0.6556028"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hist(population_ages, breaks=20)  # create histogram of population\n",
    "\n",
    "skewness(population_ages)         # check the skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram shows a distribution with right skew, which is confirmed by the skewness measurement of 0.6556. The sample we drew should have roughly the same shape and skewness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.670960675526386"
      ],
      "text/latex": [
       "0.670960675526386"
      ],
      "text/markdown": [
       "0.670960675526386"
      ],
      "text/plain": [
       "[1] 0.6709607"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hist(sample_ages, breaks=20)   # create histogram of the sample\n",
    "\n",
    "skewness(sample_ages)          # check the skewness (point estimate of skewness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample has roughly the same skew as the underlying population. This suggests that we can't apply techniques that assume a normal distribution to this data set. In reality, we can, thanks the central limit theorum.\n",
    "\n",
    "The central limit theorum is one of the most important results of probabilty theory and serves as the foundation of many methods of statistical analysis. At a high level, the theorum states the distribution of many sample means, known as a sampling distribution, will be normally distributed. This rule holds even if the underlying distribuion itself is not normally distributed. As a result we can treat our a sample mean as if it were drawn normal distribution. \n",
    "\n",
    "To illustrate, let's create a sampling distribution by taking 200 samples from our population and then making 200 point estimates of the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(12)\n",
    "point_estimates <- c()    # create an empty vector to hold results\n",
    "\n",
    "num_samples <- 200        # initialize number of samples to take\n",
    "\n",
    "for (x in 1:num_samples){         # draw 200 samples and make 200 point estimates\n",
    "    sample <- sample(population_ages, size=1000)\n",
    "    point_estimates <- c(point_estimates, mean(sample))\n",
    "}\n",
    "\n",
    "# plot(density(point_estimates))  # plot the sampling distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sampling distribution appears to be roughly normal, having significantly less skew than the original distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "-0.0130738593557108"
      ],
      "text/latex": [
       "-0.0130738593557108"
      ],
      "text/markdown": [
       "-0.0130738593557108"
      ],
      "text/plain": [
       "[1] -0.01307386"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skewness(point_estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, the mean of the sampling distribution approaches the true population mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "51.2249750096931"
      ],
      "text/latex": [
       "51.2249750096931"
      ],
      "text/markdown": [
       "51.2249750096931"
      ],
      "text/plain": [
       "[1] 51.22498"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "0.00613782359863535"
      ],
      "text/latex": [
       "0.00613782359863535"
      ],
      "text/markdown": [
       "0.00613782359863535"
      ],
      "text/plain": [
       "[1] 0.006137824"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(point_estimates)\n",
    "\n",
    "mean(point_estimates)-true_mean    # difference between true mean and average of 200 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more samples we take, the better our estimate of the population parmeter is likely to be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A point estimate can give you a rough idea of a population parameter like the mean, but estimates are prone to error and taking multiple samples to get improved estimates may not be feasible. A confidence interval is a range of values above and below a point estimate that captures the true population parameter at some predetermined confidence level. For example, if you want to have a 95% chance of capturing the true population parameter with a point estimate and a corresponding confidence interval, you's set your confidence level to 95%. Higher confidence levels result in a wider confidence intevals.\n",
    "\n",
    "Calculate a confidence interval by taking a point esimate and then adding and subtracting a margin of error to create a range. Margin of error is based on your desired confidence level, the spread of the data and the size of your sample. The way you calculate the margin of error depends on whether you know the standard deviation of the population or not. \n",
    "\n",
    "If you know the standard deviation of the population, the margin of error is equal to:\n",
    "\n",
    "$$z * \\frac{\\sigma}{\\sqrt{n}}$$\n",
    "\n",
    "Where Ïƒ is the population standard deviation, n is sample size, and z is a number known as the z-critical value. The z critical value is the number of standard deviations you'd have to go from the mean of the normal distribution to capture the proportion of the data associated with the desired confidence level. For instance, we know that roughly 95% of the data in a normal distribution lies within 2 standard deviations of the mean, so we could use 2 as the z-critical value for a 95% confidence interval (although it is more exact to get z-critical values with qnorm().). \n",
    "\n",
    "Let's calculate a 95% confidence for our mean point estimate in R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"z-critical value:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "1.95996398454005"
      ],
      "text/latex": [
       "1.95996398454005"
      ],
      "text/markdown": [
       "1.95996398454005"
      ],
      "text/plain": [
       "[1] 1.959964"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Confidence interval:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>51.0547629584072</li>\n",
       "\t<li>53.2724548862699</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 51.0547629584072\n",
       "\\item 53.2724548862699\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 51.0547629584072\n",
       "2. 53.2724548862699\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 51.05476 53.27245"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set.seed(10)\n",
    "sample_size <- 1000\n",
    "sample_ages <- sample(population_ages, size=sample_size)  # take a sampe of 1000 ages\n",
    "\n",
    "sample_mean <- mean(sample_ages)  # get the sample mean\n",
    "\n",
    "z_critical <- qnorm(0.975)        # get the z-critical value for a 95% confidence interval*\n",
    "\n",
    "print(\"z-critical value:\")\n",
    "z_critical                        # check the z-critical value\n",
    "\n",
    "pop_stdev <- sd(population_ages)  # get the population standard deviation\n",
    "\n",
    "margin_of_error <- z_critical * (pop_stdev / sqrt(sample_size)) # calculate margin of error\n",
    "\n",
    "confidence_interval  <- c(sample_mean - margin_of_error,  # calculate the the interval\n",
    "                          sample_mean + margin_of_error)  \n",
    "\n",
    "print(\"Confidence interval:\")\n",
    "confidence_interval               # check the interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: We use qnorm(0.975) to get the desired z critical value instead of qnorm(0.95) because the distribtution has two tails.\n",
    "\n",
    "Notice that the confidence interval we calculated captures the true population mean of 51.2188.\n",
    "\n",
    "Let's create several confidence intervals and plot them to get a better sense of what it means to \"capture\" the true mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(12)\n",
    "sample_size <- 1000\n",
    "\n",
    "intervals <- c()  # create and store 25 intervals\n",
    " \n",
    "for (sample in 1:25){\n",
    "sample_ages <- sample(population_ages, size=sample_size)  # take a sampe of 1000 ages\n",
    "\n",
    "sample_mean <- mean(sample_ages)  # get the sample mean\n",
    "\n",
    "z_critical <- qnorm(0.975)        # get the z-critical value for a 95% confidence interval*\n",
    "\n",
    "pop_stdev <- sd(population_ages)  # get the population standard deviation\n",
    "\n",
    "margin_of_error <- z_critical * (pop_stdev / sqrt(sample_size)) # calculate margin of error\n",
    "\n",
    "confidence_interval  <- c(sample_mean - margin_of_error,  # calculate the the interval\n",
    "                          sample_mean + margin_of_error)  \n",
    "\n",
    "intervals <- c(intervals, confidence_interval)    \n",
    "}\n",
    "\n",
    "interval_df <- data.frame(t(matrix(intervals,2,25)))  # store intervals as data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot confidence intervals and show the true mean\n",
    "\n",
    "my_plot <- ggplot(data=interval_df, aes(x=1:nrow(interval_df))) +\n",
    "                geom_errorbar(aes(ymax = X2, ymin = X1)) +\n",
    "                geom_point(aes(y=rowMeans(interval_df)), shape=1, size=3) +\n",
    "                geom_abline(intercept=true_mean, slope=0,color=\"red\",lwd=1) +\n",
    "                ylab(\"Interval Range (Red Line=True Mean)\") +\n",
    "                xlab(\"Interval Number\")\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Notice that in the plot above, all but one of the 95% confidence intervals overlap the red line marking the true mean. This is to be expected: since a 95% confidence interval captures the true mean 95% of the time, we'd expect our interval to miss the true mean 5% of the time.\n",
    "\n",
    "If you don't know the standard deviation of the population, you have to use the standard deviation of your sample as a stand in when creating confidence intervals. Since the sample standard deviation may not match the population parameter the interval will have more error when you don't know the population standard deviation. To account for this error, we use what's known as a t-critical value instead of the z-critical value. The t-critical value is drawn from what's known as a t-distribution--a distribution that closely resembles the normal distribution but that gets wider and wider as the sample size falls. The t-distribution is built into R and has the nickname \"t\" so the functions for working with it are rt(), qt(), pt() and dt(). \n",
    "\n",
    "Let's take a new, smaller sample and then create a confidence interval without the population standard deviation, using the t-distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"t-critical value:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "2.06389856162803"
      ],
      "text/latex": [
       "2.06389856162803"
      ],
      "text/markdown": [
       "2.06389856162803"
      ],
      "text/plain": [
       "[1] 2.063899"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Confidence interval:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>43.0647995671816</li>\n",
       "\t<li>64.3762991570332</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 43.0647995671816\n",
       "\\item 64.3762991570332\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 43.0647995671816\n",
       "2. 64.3762991570332\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 43.0648 64.3763"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set.seed(12)\n",
    "smaller_sample <- sample(population_ages, size=25)  \n",
    "\n",
    "sample_mean <- mean(smaller_sample) # get the sample mean\n",
    "\n",
    "t_critical <- qt(0.975, df=24)      # get the t-critical value for a 95% confidence interval*\n",
    "\n",
    "print(\"t-critical value:\")\n",
    "t_critical                          # check the t-critical value\n",
    "\n",
    "sample_stdev <- sd(smaller_sample)  # get the sample standard deviation\n",
    "\n",
    "margin_of_error <- t_critical * (sample_stdev / sqrt(25)) # calculate margin of error\n",
    "\n",
    "confidence_interval  <- c(sample_mean - margin_of_error,  # calculate the the interval\n",
    "                          sample_mean + margin_of_error)  \n",
    "print(\"Confidence interval:\")\n",
    "confidence_interval  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: when using the t-distribution, you have to supply the degrees of freedom (df). For this type of one test, the degrees of freedom is equal to the sample size minus 1. If you have a large sample size, the t-distribution approaches the normal distribution.\n",
    "\n",
    "Notice that the t-critical value is larger than the z-critical value we used for 95% confidence interval. This allows the confidence interval to cast a larger net to make up for the variabilty caused by using the sample standard deviation in place of the population standard deviation. The end result is a much wider confidence interval (an interval with a larger margin of error.).\n",
    "\n",
    "If you have a large sample, the t-critical value will approach the z-critical value so there is little difference bewteen using the normal distribution vs. the t-distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "1.95996398454005"
      ],
      "text/latex": [
       "1.95996398454005"
      ],
      "text/markdown": [
       "1.95996398454005"
      ],
      "text/plain": [
       "[1] 1.959964"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "1.96234146113345"
      ],
      "text/latex": [
       "1.96234146113345"
      ],
      "text/markdown": [
       "1.96234146113345"
      ],
      "text/plain": [
       "[1] 1.962341"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the difference bewteen critical values with a sample size of 1000\n",
    "qnorm(0.975)                \n",
    "qt(0.975, df= 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of calculating a confidence interval for a mean point estimate by hand, you can have R calculate it for you using the t.test() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tOne Sample t-test\n",
       "\n",
       "data:  smaller_sample\n",
       "t = 10.4051, df = 24, p-value = 2.251e-10\n",
       "alternative hypothesis: true mean is not equal to 0\n",
       "95 percent confidence interval:\n",
       " 43.0648 64.3763\n",
       "sample estimates:\n",
       "mean of x \n",
       " 53.72055 \n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test(smaller_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the test output includes a 95% confidence interval that matches the result we calcualted (we'll discuss t.test() in more deail in the next lesson).\n",
    "\n",
    "We can also make a confidence interval for a point estimate of a population proportion. In this case, the margin of error equals:\n",
    "\n",
    "$$z * \\sqrt{\\frac{p(1-p)}{n}}$$\n",
    "\n",
    "Where z is the z-critical value for our confidence level, p is the point estimate of the population proportion and n is the sample size. Let's calculate a 95% confidence interval for Hispanics according to the sample proportion we calculated earlier (0.204):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.179024182713281</li>\n",
       "\t<li>0.228975817286719</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.179024182713281\n",
       "\\item 0.228975817286719\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.179024182713281\n",
       "2. 0.228975817286719\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.1790242 0.2289758"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_critical <- qnorm(0.975)    # record z-critical value\n",
    "\n",
    "p <- 0.204                    # point estimate of proportion\n",
    "\n",
    "n <- 1000                     # sample size\n",
    "\n",
    "margin_of_error <- z_critical * sqrt((p*(1-p))/n)\n",
    "\n",
    "confidence_interval  <- c(p - margin_of_error,  # calculate the the interval\n",
    "                          p + margin_of_error) \n",
    "\n",
    "confidence_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, the confidence interval captured the true population parameter of 0.2.\n",
    "\n",
    "As with the confidence interval for the mean, you can use a built in R function to get a confidence interval for a population proportion instead of calculating it by hand. In this case, we use the prop.test() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\t1-sample proportions test with continuity correction\n",
       "\n",
       "data:  204 out of 1000, null probability 0.5\n",
       "X-squared = 349.281, df = 1, p-value < 2.2e-16\n",
       "alternative hypothesis: true p is not equal to 0.5\n",
       "95 percent confidence interval:\n",
       " 0.1797036 0.2306071\n",
       "sample estimates:\n",
       "    p \n",
       "0.204 \n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop.test(x=204,      # number of observations\n",
    "          n=1000)     # total number of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output above, note that the 95% confidence interval listed roughly matches the one we calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Estimating population parameters through sampling is a simple, yet powerful form of inference. Point estimates combined with error margins let us create confidence intervals that capture the true population parameter with high probability. R's built in probability distribution and test functions make it easy to calcualte confidence intervals quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Time: Introduction to R Part 24: Hypothesis Testing and T-Tests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
